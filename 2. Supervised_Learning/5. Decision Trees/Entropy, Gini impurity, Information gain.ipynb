{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy, Gini impurity and information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libararies\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample dataset\n",
    "n_A = 4\n",
    "n_B = 6\n",
    "total = n_A + n_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of A:  0.4\n",
      "Proportion of B:  0.6\n"
     ]
    }
   ],
   "source": [
    "#propotion of A and B\n",
    "p_A = n_A / total\n",
    "p_B = n_B / total\n",
    "\n",
    "print(\"Proportion of A: \", p_A)\n",
    "print(\"Proportion of B: \", p_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of A and B:  0.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "#entropy of A and B\n",
    "entropy = -p_A * math.log2(p_A) - p_B * math.log2(p_B)\n",
    "print(\"Entropy of A and B: \", entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini impurity:  0.48\n"
     ]
    }
   ],
   "source": [
    "#gini impurity\n",
    "gini = 1 - p_A**2 - p_B**2\n",
    "print(\"Gini impurity: \", gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of split dataset 1:  0.8112781244591328\n",
      "Entropy of split dataset 2:  1.0\n",
      "Information gain:  0.046439344671015514\n"
     ]
    }
   ],
   "source": [
    "#split dataset\n",
    "n_1_A, n_1_B = 1, 3\n",
    "n_2_A, n_2_B = 3, 3\n",
    "\n",
    "#proportion of split dataset\n",
    "p_1_A = n_1_A / (n_1_A + n_1_B)\n",
    "p_1_B = n_1_B / (n_1_A + n_1_B)\n",
    "\n",
    "#entropy of split dataset\n",
    "entropy_1 = -p_1_A * math.log2(p_1_A) - p_1_B * math.log2(p_1_B)\n",
    "print(\"Entropy of split dataset 1: \", entropy_1)\n",
    "\n",
    "#proportion of split dataset\n",
    "p_2_A = n_2_A / (n_2_A + n_2_B)\n",
    "p_2_B = n_2_B / (n_2_A + n_2_B)\n",
    "\n",
    "#entropy of split dataset\n",
    "entropy_2 = -p_2_A * math.log2(p_2_A) - p_2_B * math.log2(p_2_B)\n",
    "print(\"Entropy of split dataset 2: \", entropy_2)\n",
    "\n",
    "#information gain\n",
    "info_gain = entropy - (n_1_A + n_1_B) / total * entropy_1 - (n_2_A + n_2_B) / total * entropy_2\n",
    "print(\"Information gain: \", info_gain)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
